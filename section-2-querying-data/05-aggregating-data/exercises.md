# Exercise: Aggregating Data

## Prerequisites
- Completed previous exercises (Filtering, NULLs)
- The `products` table with all previously inserted data

## Additional Setup

Add sales data to enable meaningful aggregation exercises. We'll create a `sales` table and populate it.

```sql
CREATE TABLE sales (
    sale_id SERIAL PRIMARY KEY,
    product_id INTEGER,
    quantity INTEGER,
    unit_price DECIMAL(10, 2),
    sale_date DATE,
    region VARCHAR(50)
);

-- Insert sample sales data (combining multiple inserts for brevity)
INSERT INTO sales (product_id, quantity, unit_price, sale_date, region) VALUES
-- Electronics Sales
(1, 5, 29.99, '2025-01-01', 'North'), (1, 3, 29.99, '2025-01-02', 'South'), (1, 10, 28.00, '2025-01-05', 'East'),
(2, 2, 89.99, '2025-01-01', 'North'), (2, 1, 89.99, '2025-01-03', 'West'),
(3, 15, 49.99, '2025-01-02', 'North'), (3, 8, 45.00, '2025-01-04', 'East'), (3, 20, 42.00, '2025-01-10', 'South'),
-- Furniture Sales
(4, 1, 34.99, '2025-01-05', 'West'), (4, 2, 34.99, '2025-01-12', 'West'),
(7, 1, 199.99, '2025-01-08', 'North'), (7, 4, 180.00, '2025-01-15', 'South'),
-- Office Supplies Sales
(9, 50, 4.99, '2025-01-01', 'East'), (9, 20, 4.99, '2025-01-02', 'East'), (9, 100, 4.50, '2025-01-10', 'North'),
(10, 10, 12.99, '2025-01-03', 'South'), (10, 5, 12.99, '2025-01-05', 'West'),
-- NULL product sales (orphaned records or miscellaneous)
(NULL, 1, 100.00, '2025-01-20', 'North');
```

---

## Exercise 1: Basic Aggregations

### Context
Aggregate functions collapse multiple rows into a single value. They are the foundation of data analysis in SQL.

### Tasks

#### Task 1.1: Simple Counts and Sums
1. Count the total number of sales records
2. Calculate the total revenue (sum of `quantity * unit_price`) from all sales
3. Calculate the total number of items sold across all transactions
4. Find the date of the very first sale and the very last sale

#### Task 1.2: Averages and Precision
1. Calculate the average unit price of items sold
2. Calculate the average order value (revenue per sale_id). Note: revenue per sale is `quantity * unit_price`
3. **Challenge**: Why might `AVG(quantity * unit_price)` give a different result than `SUM(quantity * unit_price) / COUNT(*)` if there were NULLs?

#### Task 1.3: Min/Max Analysis
1. Find the highest unit price ever sold
2. Find the largest quantity sold in a single transaction
3. Find the lowest revenue generated by a single transaction

---

## Exercise 2: GROUP BY Fundamentals

### Context
`GROUP BY` allows you to apply aggregates to subsets of data. The golden rule: any non-aggregated column in the SELECT list MUST appear in the GROUP BY clause.

### Tasks

#### Task 2.1: Grouping by Single Column
1. Calculate total revenue per region
2. Find the number of sales transactions per product_id
3. Calculate the average quantity sold per product_id

#### Task 2.2: Grouping by Multiple Columns
1. Calculate total revenue per region AND product_id
2. Find the number of sales per region per day
3. **Challenge**: Order the results by region (A-Z) and then by highest revenue first

#### Task 2.3: Grouping by Expressions
1. Calculate total sales by month (extract month from sale_date)
2. Calculate total sales by "weekend vs weekday" (you'll need a way to determine day of week)
3. Calculate sales for "High Value" (> $50) vs "Low Value" items based on unit_price

---

## Exercise 3: Advanced Aggregations

### Context
PostgreSQL offers powerful aggregation features beyond simple sums and counts.

### Tasks

#### Task 3.1: STRING_AGG / ARRAY_AGG
1. For each region, list all product_ids sold there as a comma-separated string
2. For each product_id, create an array of all sale dates
3. Create a report showing each product_id and a list of regions it has been sold in (distinct regions only)

#### Task 3.2: Filtered Aggregates (FILTER clause)
1. In a single query, calculate:
   - Total revenue
   - Revenue from 'North' region
   - Revenue from 'South' region
   Using the `FILTER (WHERE ...)` syntax.

2. Calculate the count of sales for 2024 and 2025 separately in one row.

#### Task 3.3: Statistical Aggregates
1. Calculate the standard deviation of unit prices (`STDDEV`)
2. Calculate the variance of quantities sold (`VARIANCE`)
3. Explain what a high standard deviation in sales quantity might indicate for inventory planning.

---

## Exercise 4: DISTINCT in Aggregates

### Context
Sometimes you need to count unique occurrences within a group.

### Tasks

#### Task 4.1: Counting Unique Values
1. Count how many *unique* products have been sold in each region
2. Count how many *unique* days had sales for each product
3. Calculate the average number of distinct products sold per day (requires a subquery or 2-step thinking)

---

## Exercise 5: GROUP BY & NULLs

### Context
Understanding how GROUP BY handles NULLs is crucial for accurate reporting.

### Tasks

#### Task 5.1: Grouping NULLs
1. Group sales by product_id. How is the NULL product_id handled?
2. Group products (from products table) by subcategory. How many groups are created?
3. **Challenge**: Write a query that groups by subcategory but replaces NULL with 'Uncategorized' *in the grouping itself*.

---

## Exercise 6: Business Intelligence Challenges

### Challenge 6.1: Regional Performance Report
Create a summary table showing for each region:
- Total Transactions
- Total Revenue
- Average Transaction Value
- Best Selling Product ID (by revenue) - *Hint: This might be hard without window functions, so for now just find the max revenue for a single transaction in that region*

### Challenge 6.2: Daily Sales Velocity
Calculate the daily sales velocity for each product:
- Total quantity sold
- Number of distinct days it sold
- Average quantity per day (considering only days with sales)

### Challenge 6.3: Product Contribution
For each product, calculate:
- Its total revenue
- What percentage of the global total revenue it represents
(Hint: You might need a subquery or a CTE to get the global total first)

---

## Deliverables

For each exercise, provide:
1. The SQL query
2. A brief explanation of the grouping logic
3. Sample output

**Evaluation Criteria**:
- Correct use of aggregate functions
- Adherence to GROUP BY rules (all non-aggregated columns grouped)
- Usage of Postgres specific features like `FILTER` and `STRING_AGG`
- Handling of NULLs in aggregates and groups
